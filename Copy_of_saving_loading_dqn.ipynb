{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gymnasium - An API standard for reinforcement learning with a diverse collection of reference environments\n",
        "\n",
        "Documents: https://gymnasium.farama.org/introduction/train_agent/\n",
        "\n",
        "Gymnasium is a project that provides an API (application programming interface) for all single agent reinforcement learning environments, with implementations of common environments: cartpole, pendulum, mountain-car, mujoco, atari, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines3 - Training, Saving and Loading\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL), using Stable Baselines3.\n",
        "\n",
        "It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
        "\n",
        "Examples with Collab Code: [https://stable-baselines3.readthedocs.io/en/master/guide/examples.html](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html)\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gGbS4lII8i_"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWskDE2c9WoN",
        "outputId": "bdd6e935-52e2-4fa3-f64c-cd78d6447468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (2.3.5)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a4 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.2.5)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.7.0)\n",
            "Requirement already satisfied: cloudpickle in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.1)\n",
            "Requirement already satisfied: pandas in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.0.4)\n",
            "Requirement already satisfied: filelock in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.18.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.3.2)\n",
            "Requirement already satisfied: opencv-python in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.19.0)\n",
            "Requirement already satisfied: psutil in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (7.0.0)\n",
            "Requirement already satisfied: tqdm in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (4.67.1)\n",
            "Requirement already satisfied: rich in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (14.0.0)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (0.11.0)\n",
            "Requirement already satisfied: pillow in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.8)\n",
            "Requirement already satisfied: packaging in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (6.30.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (65.5.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4) (0.1.2)\n",
            "Requirement already satisfied: colorama in c:\\pycharmprojects\\gym_jupyter\\.venv\\lib\\site-packages (from tqdm->stable-baselines3[extra]>=2.0.0a4) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install box2d-py\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Import policy, RL agent, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will use Lunar Lander environment.\n",
        "\n",
        "\"Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine. \"\n",
        "\n",
        "Lunar Lander environment: [https://gymnasium.farama.org/environments/box2d/lunar_lander/](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
        "\n",
        "![Lunar Lander](https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif)\n",
        "\n",
        "\n",
        "We chose the MlpPolicy because input of Lunar Lander is a feature vector, not images.\n",
        "\n",
        "The type of action to use (discrete/continuous) will be automatically deduced from the environment action space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'LunarLander-v3'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    \"LunarLander-v3\",\n",
        "    verbose=1,\n",
        "    exploration_final_eps=0.1,\n",
        "    target_update_interval=250,\n",
        "    tensorboard_log=\"tb_logs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl"
      },
      "source": [
        "We load a helper function to evaluate the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PeaVBGuJwK97"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEVOIY8NVeK"
      },
      "source": [
        "Let's evaluate the un-trained agent, this should be a random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xDHLMA6NFk95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\PycharmProjects\\gym_jupyter\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward=-597.00 +/- 165.98748966265896\n"
          ]
        }
      ],
      "source": [
        "# Separate env for evaluation\n",
        "eval_env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
        "\n",
        "\n",
        "# Random Agent, before training\n",
        "mean_reward, std_reward = evaluate_policy(\n",
        "    model,\n",
        "    eval_env,\n",
        "    n_eval_episodes=10,\n",
        "    deterministic=True,\n",
        ")\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train the agent and save it\n",
        "\n",
        "Warning: this may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e4cfSXIB-pTF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to tb_logs\\dqn_lunar_2\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 80.8     |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.971    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1158     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 323      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.06     |\n",
            "|    n_updates        | 55       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 82.2     |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.941    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1246     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 658      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.74     |\n",
            "|    n_updates        | 139      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.7     |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.905    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1344     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1052     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.65     |\n",
            "|    n_updates        | 237      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.1     |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.87     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1355     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1441     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.16     |\n",
            "|    n_updates        | 335      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.4     |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.835    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1376     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1828     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.08     |\n",
            "|    n_updates        | 431      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.9     |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.804    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1386     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2181     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.02     |\n",
            "|    n_updates        | 520      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.6     |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.756    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1391     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2706     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 10.2     |\n",
            "|    n_updates        | 651      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.1     |\n",
            "|    ep_rew_mean      | -247     |\n",
            "|    exploration_rate | 0.717    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3140     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.78     |\n",
            "|    n_updates        | 759      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.669    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1376     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3679     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.03     |\n",
            "|    n_updates        | 894      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | -233     |\n",
            "|    exploration_rate | 0.626    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1363     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4159     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.78     |\n",
            "|    n_updates        | 1014     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.563    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1286     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4858     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.51     |\n",
            "|    n_updates        | 1189     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 120      |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.484    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1204     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5738     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.49     |\n",
            "|    n_updates        | 1409     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -232     |\n",
            "|    exploration_rate | 0.373    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1150     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 6972     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.15     |\n",
            "|    n_updates        | 1717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 730      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 10972    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.948    |\n",
            "|    n_updates        | 2717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 673      |\n",
            "|    time_elapsed     | 22       |\n",
            "|    total_timesteps  | 14972    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.03     |\n",
            "|    n_updates        | 3717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 269      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 647      |\n",
            "|    time_elapsed     | 26       |\n",
            "|    total_timesteps  | 17194    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.808    |\n",
            "|    n_updates        | 4273     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 31       |\n",
            "|    total_timesteps  | 19908    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.49     |\n",
            "|    n_updates        | 4951     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 626      |\n",
            "|    time_elapsed     | 35       |\n",
            "|    total_timesteps  | 22303    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.17     |\n",
            "|    n_updates        | 5550     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 630      |\n",
            "|    time_elapsed     | 36       |\n",
            "|    total_timesteps  | 23030    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.9      |\n",
            "|    n_updates        | 5732     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 605      |\n",
            "|    time_elapsed     | 41       |\n",
            "|    total_timesteps  | 25243    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.888    |\n",
            "|    n_updates        | 6285     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 45       |\n",
            "|    total_timesteps  | 27352    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.877    |\n",
            "|    n_updates        | 6812     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 28622    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 7130     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 595      |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 29812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.738    |\n",
            "|    n_updates        | 7427     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 328      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 571      |\n",
            "|    time_elapsed     | 55       |\n",
            "|    total_timesteps  | 31522    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.33     |\n",
            "|    n_updates        | 7855     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 56       |\n",
            "|    total_timesteps  | 32608    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 8126     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 346      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 564      |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 34961    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.623    |\n",
            "|    n_updates        | 8715     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -216     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 560      |\n",
            "|    time_elapsed     | 66       |\n",
            "|    total_timesteps  | 37477    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.586    |\n",
            "|    n_updates        | 9344     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 399      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 551      |\n",
            "|    time_elapsed     | 74       |\n",
            "|    total_timesteps  | 40991    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.926    |\n",
            "|    n_updates        | 10222    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 434      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 530      |\n",
            "|    time_elapsed     | 84       |\n",
            "|    total_timesteps  | 44889    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.47     |\n",
            "|    n_updates        | 11197    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 468      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 522      |\n",
            "|    time_elapsed     | 93       |\n",
            "|    total_timesteps  | 48673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.2      |\n",
            "|    n_updates        | 12143    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 505      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 510      |\n",
            "|    time_elapsed     | 103      |\n",
            "|    total_timesteps  | 52673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.888    |\n",
            "|    n_updates        | 13143    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 540      |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 113      |\n",
            "|    total_timesteps  | 56673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.717    |\n",
            "|    n_updates        | 14143    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 574      |\n",
            "|    ep_rew_mean      | -161     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 120      |\n",
            "|    total_timesteps  | 60553    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.681    |\n",
            "|    n_updates        | 15113    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 604      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 129      |\n",
            "|    total_timesteps  | 64108    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.792    |\n",
            "|    n_updates        | 16001    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 635      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 484      |\n",
            "|    time_elapsed     | 139      |\n",
            "|    total_timesteps  | 67656    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.525    |\n",
            "|    n_updates        | 16888    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 663      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 147      |\n",
            "|    total_timesteps  | 71168    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.902    |\n",
            "|    n_updates        | 17766    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 690      |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 156      |\n",
            "|    total_timesteps  | 74700    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.971    |\n",
            "|    n_updates        | 18649    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 715      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 476      |\n",
            "|    time_elapsed     | 164      |\n",
            "|    total_timesteps  | 78450    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.825    |\n",
            "|    n_updates        | 19587    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 708      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 476      |\n",
            "|    time_elapsed     | 171      |\n",
            "|    total_timesteps  | 81817    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.694    |\n",
            "|    n_updates        | 20429    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 703      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 473      |\n",
            "|    time_elapsed     | 180      |\n",
            "|    total_timesteps  | 85275    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.754    |\n",
            "|    n_updates        | 21293    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 714      |\n",
            "|    ep_rew_mean      | -99.6    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 188      |\n",
            "|    total_timesteps  | 88565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.479    |\n",
            "|    n_updates        | 22116    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 719      |\n",
            "|    ep_rew_mean      | -83.1    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 470      |\n",
            "|    time_elapsed     | 195      |\n",
            "|    total_timesteps  | 91809    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.473    |\n",
            "|    n_updates        | 22927    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 722      |\n",
            "|    ep_rew_mean      | -68.9    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 201      |\n",
            "|    total_timesteps  | 94468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.445    |\n",
            "|    n_updates        | 23591    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 738      |\n",
            "|    ep_rew_mean      | -58.4    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 205      |\n",
            "|    total_timesteps  | 96843    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.2      |\n",
            "|    n_updates        | 24185    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 743      |\n",
            "|    ep_rew_mean      | -52      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 474      |\n",
            "|    time_elapsed     | 209      |\n",
            "|    total_timesteps  | 99505    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.723    |\n",
            "|    n_updates        | 24851    |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Save every 10000 steps\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_path=\"models/dqn_lunar\",\n",
        "    save_freq=10000,\n",
        "    name_prefix=\"dqn_lunar\",\n",
        ")\n",
        "# Train the agent\n",
        "model.learn(total_timesteps=int(1e5), callback=checkpoint_callback, tb_log_name=\"dqn_lunar\")\n",
        "# Save the agent optionally\n",
        "model.save(\"dqn_lunar_final\")\n",
        "del model  # delete trained model to demonstrate loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T31dZJYNrJwF"
      },
      "source": [
        "## Load the trained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1ExgtyZrIA6"
      },
      "outputs": [],
      "source": [
        "model = DQN.load(\"dqn_lunar_final\")\n",
        "\n",
        "# load a specific checkpoint file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
        "\n",
        "# add render_mode=\"human\" to visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ygl_gVmV_QP7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\PycharmProjects\\gym_jupyter\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward=-96.72 +/- 23.48040326224806\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=5, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
