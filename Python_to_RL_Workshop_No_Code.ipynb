{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python to Reinforcement Learning for beginner\n",
    "\n",
    "### Lesson Plan:\n",
    "1. Python Basics\n",
    "2. Control Flow & Functions\n",
    "3. Creating and using import \n",
    "4. NumPy & Basic Math\n",
    "5. Introduction to Reinforcement Learning\n",
    "6. Simple RL Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Basics (30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables and Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists (arrays)\n",
    "\n",
    "# print the lists\n",
    "\n",
    "# Adding to list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries (key-value pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Control Flow & Functions (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If-else statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating and using import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a library random\n",
    "\n",
    "# random.random() returns a floating-point number ‚â• 0.0 and < 1.0.\n",
    "# Useful for simulating probabilities (e.g., chance of success or failure).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a guessing game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a random number between 1 and 100\n",
    "\n",
    "# while True\n",
    "#   Let user input a number\n",
    "#   attempt = attempt + 1\n",
    "#   if user input < random generated number, print \"too low\"\n",
    "#   else if user input > random generated number, print \"too high\"\n",
    "#   else print \"Correct\" and show the number of attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NumPy & Basic Math (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pip install library numpy\n",
    "\n",
    "\n",
    "# Creating arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Understanding the Dot Product with NumPy\n",
    "\n",
    "The **dot product** (also known as the **scalar product**) is a way to multiply two vectors and get a **single scalar value**.\n",
    "\n",
    "### üìò Formula\n",
    "\n",
    "For two vectors **A** and **B**:\n",
    "\n",
    "dot(A, B) = A‚ÇÅ * B‚ÇÅ + A‚ÇÇ * B‚ÇÇ + A‚ÇÉ * B‚ÇÉ + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Matrix Multiplication in NumPy\n",
    "\n",
    "Matrix multiplication combines two 2D arrays using the dot product of rows and columns.<p>\n",
    "Each element in the resulting matrix is calculated as the dot product of a row from matrix A and a column from matrix B.\n",
    "\n",
    "### üëá Example 1:\n",
    "\n",
    "Let: <p>\n",
    "A = [[1, 2], <p>\n",
    "     &emsp;&emsp;[3, 4]] <p>\n",
    "<p>\n",
    "B = [[5, 6], <p>\n",
    "     &emsp;&emsp;[7, 8]]\n",
    "<p>\n",
    "Then:\n",
    "\n",
    "A √ó B = [[1√ó5 + 2√ó7, 1√ó6 + 2√ó8], [3√ó5 + 4√ó7, 3√ó6 + 4√ó8]] <p>\n",
    "A x B = [[19, 22], [43, 50]]\n",
    "\n",
    "### üëá Example 2: (2x3)@(3x2) = (2x2)\n",
    "\n",
    "A = [[1, 2, 3], <p> \n",
    "     &emsp;&emsp;[4, 5, 6]]\n",
    "<p>\n",
    "B = [[7, 8], <p>\n",
    "     &emsp;&emsp;[9, 10], <p>\n",
    "     &emsp;&emsp;[11, 12]]\n",
    "<p>\n",
    "Then:\n",
    "\n",
    "A x B = [[1x7+2x9+3x11, 1x8+2x10+3x12], [4x7+5x9+6x11, 4x8+5x10+6x12]]\n",
    "\n",
    "A x B = [[1x7+2x9+3x11, 1x8+2x10+3x12], \n",
    "         [4x7+5x9+6x11, 4x8+5x10+6x12]]\n",
    "\n",
    "A x B = [[58, 64], \n",
    "         [139, 154]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random numbers (important for RL)\n",
    "# generate 3 random numbers between 0 and 1\n",
    "\n",
    "\n",
    "# Random number between 0-99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Introduction to Reinforcement Learning (30 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Reinforcement Learning?\n",
    "\n",
    "Reinforcement Learning (RL) is a type of machine learning where an **agent** learns to make decisions by performing **actions** in an **environment** to maximize some notion of **reward**.\n",
    "\n",
    "Key concepts:\n",
    "- **Agent**: The learner/decision maker\n",
    "- **Environment**: The world the agent interacts with\n",
    "- **State**: Current situation of the agent\n",
    "- **Action**: What the agent can do\n",
    "- **Reward**: Feedback from the environment\n",
    "- **Policy**: Strategy the agent uses to choose actions\n",
    "\n",
    "![RL Diagram](https://www.guru99.com/images/1/082319_0514_Reinforceme3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example: Multi-Armed Bandit\n",
    "\n",
    "Imagine you have 3 slot machines (\"one-armed bandits\") with different payout probabilities. How do you learn which one is best?\n",
    "\n",
    "- **States**: Which machine you're at\n",
    "- **Actions**: Which machine to play\n",
    "- **Reward**: Money won (1) or lost (0)\n",
    "- **Policy**: Strategy for choosing machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Simple RL Example (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a simple bandit problem\n",
    "import numpy as np\n",
    "\n",
    "# True probability of winning for each machine\n",
    "true_probs = [0.3, 0.5, 0.7]  # Machine 0, 1, 2\n",
    "\n",
    "class Bandit:\n",
    "    def __init__(self, true_probs):\n",
    "        self.true_probs = true_probs\n",
    "        \n",
    "    def pull(self, arm):\n",
    "        # Return 1 with probability of the arm, else 0\n",
    "        return 1 if np.random.random() < self.true_probs[arm] else 0\n",
    "\n",
    "# Create our bandit environment\n",
    "bandit = Bandit(true_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RL agent - Epsilon-Greedy\n",
    "class RLAgent:\n",
    "    def __init__(self, n_arms, epsilon=0.1):\n",
    "        self.n_arms = n_arms\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.q_values = np.zeros(n_arms)  # Estimated value of each arm\n",
    "        self.counts = np.zeros(n_arms)    # Number of times each arm was pulled\n",
    "    \n",
    "    def choose_action(self):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            # Explore: choose random arm\n",
    "            return np.random.randint(self.n_arms)\n",
    "        else:\n",
    "            # Exploit: choose best known arm\n",
    "            return np.argmax(self.q_values)\n",
    "    \n",
    "    def update(self, arm, reward):\n",
    "        # Update the estimated value of the arm\n",
    "        self.counts[arm] += 1\n",
    "        self.q_values[arm] += (reward - self.q_values[arm]) / self.counts[arm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train our agent!\n",
    "agent = RLAgent(n_arms=3, epsilon=0.1)\n",
    "n_trials = 1000\n",
    "rewards = []\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    arm = agent.choose_action()\n",
    "    reward = bandit.pull(arm)\n",
    "    agent.update(arm, reward)\n",
    "    rewards.append(reward)\n",
    "\n",
    "print(\"Estimated Q-values:\", agent.q_values)\n",
    "print(\"True probabilities:\", true_probs)\n",
    "print(\"Total reward:\", sum(rewards))\n",
    "print(\"Optimal arm found:\", np.argmax(agent.q_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Happened?\n",
    "\n",
    "1. Our agent started with no knowledge (all Q-values = 0)\n",
    "2. It explored randomly at first (10% of the time)\n",
    "3. Over time, it learned which machine pays best\n",
    "4. Eventually it mostly chose the best machine (arm 2 with 70% win rate)\n",
    "\n",
    "This is the essence of RL: Learning through trial and error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If you enjoyed this, you might explore:\n",
    "- More complex RL environments (like CartPole)\n",
    "- Deep Reinforcement Learning (combining neural networks with RL)\n",
    "- Applications: Game playing (AlphaGo), robotics, recommendation systems\n",
    "\n",
    "### Resources\n",
    "- [Reinforcement Learning Introduction (YouTube)](https://www.youtube.com/watch?v=JgvyzIkgxF0)\n",
    "- [OpenAI Gym (RL environments)](https://gym.openai.com/)\n",
    "- [Python for Beginners](https://www.python.org/about/gettingstarted/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
